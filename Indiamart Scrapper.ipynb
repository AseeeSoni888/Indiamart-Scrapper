{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c584df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_4296/666372082.py:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(executable_path=self.driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter OTP\n",
      "4820\n",
      "    Category                                    Name  \\\n",
      "0       TARP  Blue Woven Truck Waterproof Tarpaulins   \n",
      "1       TARP                      Lamifab Industries   \n",
      "2       TARP                  Plain Truck Tarpaulins   \n",
      "3       TARP        Gujarat Craft Industries Limited   \n",
      "4       TARP              Waterproof Truck Tarpaulin   \n",
      "..       ...                                     ...   \n",
      "168     TARP                      Blue PVC Tarpaulin   \n",
      "169     TARP                     Gulati Canvas Store   \n",
      "170     TARP   Modern Car Tarpaulins, For Industrial   \n",
      "171     TARP       Rainproof Exports Private Limited   \n",
      "172     TARP                PVC Coated Yellow Tirpal   \n",
      "\n",
      "                                               Address  \n",
      "0    Plot No. 4702,4703,4704,4705& 4604, 4605 , Pla...  \n",
      "1    No. 431, Santej-Vadsar Road, Tal. Kalol, Kalol...  \n",
      "2    Plot No 401 402 403 404 Paraj Station Road Mah...  \n",
      "3    gala No 5 Shed No 2 Bombay Agra Road Hanuman S...  \n",
      "4    Survey No. 79, N. H. 27, Village Shapar, Pipla...  \n",
      "..                                                 ...  \n",
      "168  Plot No. C-1/6, GIDC, Near GIDC Police Station...  \n",
      "169  No. 3, Amartalla Lane, Ground Floor, Canning S...  \n",
      "170  87, Hemant Sales Corporation, Azad Market, Bho...  \n",
      "171  133/276, Transport Nagar,, Shyam Nagar, Kanpur...  \n",
      "172  0, Ring Road No.2, Bhanpuri, Raipur,, Bhanpuri...  \n",
      "\n",
      "[173 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class IndiaMartScraper:\n",
    "    def __init__(self, driver_path):\n",
    "        self.driver_path = driver_path\n",
    "        self.driver = webdriver.Chrome(executable_path=self.driver_path)\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "        self.df = pd.DataFrame(columns=['Category', 'Name', 'Address'])\n",
    "\n",
    "    def open_website(self, url):\n",
    "        self.driver.get(url)\n",
    "        self.driver.maximize_window()\n",
    "\n",
    "    def search_product(self, search_text,id):\n",
    "        search_box = self.driver.find_element(By.ID, f'{id}') #search-input\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(search_text)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    def sign_in(self, phone_number):\n",
    "        button = self.wait.until(EC.element_to_be_clickable((By.ID, 'user_sign_in')))\n",
    "        button.click()\n",
    "        cn = self.wait.until(EC.element_to_be_clickable((By.ID, 'mobile')))\n",
    "        cn.send_keys(phone_number)\n",
    "        cn.send_keys(Keys.RETURN)\n",
    "\n",
    "    def generate_otp(self):\n",
    "        time.sleep(20)  # Wait for the OTP to be generated\n",
    "        button = self.driver.find_element(By.ID, 'passwordbtn1')\n",
    "        #time.sleep(20)\n",
    "        button.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    def enter_otp(self, otp):\n",
    "        for i, char in enumerate(otp):\n",
    "            element = self.wait.until(EC.visibility_of_element_located((By.XPATH, f\"//input[@id='{['first', 'second', 'third', 'fourth'][i]}' and contains(@class, 'mobbox1 f1 border_black1')]\")))\n",
    "            element.send_keys(char)\n",
    "\n",
    "    def scroll_to_bottom(self):\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "    def click_show_more_results(self):\n",
    "        element = self.wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='showmoreresultsdiv']/button[text()='Show more results']\")))\n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        self.driver.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "    def scrape_data(self, search_text):\n",
    "        name_elements = self.wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'cardlinks')))\n",
    "        #contact_elements = self.wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'pns_h.duet.fwb')))\n",
    "        #address_elements = self.wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'tac.wpw')))\n",
    "        address_elements = self.wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'span.db.to-txt-area.lh16.tal p.tac.wpw')))\n",
    "\n",
    "        \n",
    "        names = [el.text for el in name_elements]\n",
    "        #contacts = [el.text for el in contact_elements]\n",
    "        addresses = [el.get_attribute('textContent') for el in address_elements]\n",
    "        \n",
    "\n",
    "        for name, address in zip(names, addresses):\n",
    "            self.df = self.df.append({'Category': search_text, 'Name': name, 'Address': address}, ignore_index=True)\n",
    "\n",
    "    def close_browser(self):\n",
    "        self.driver.quit()\n",
    "        \n",
    "    def Get_Data(self):\n",
    "        data = pd.read_excel('Product-Category.xlsx')\n",
    "        for i in range(1,len(data['Seller'])):\n",
    "            search_text=data['Seller'][i]\n",
    "            self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            self.search_product(search_text,'search_string')\n",
    "            for j in range(10):\n",
    "                time.sleep(5)\n",
    "                self.click_show_more_results()\n",
    "                time.sleep(5)\n",
    "                self.scroll_to_bottom()\n",
    "                self.scrape_data(search_text)\n",
    "    \n",
    "    def run(self, url, search_text, phone_number):\n",
    "        try:\n",
    "            self.open_website(url)\n",
    "            self.search_product(search_text,'search-input')\n",
    "            self.sign_in(phone_number)\n",
    "            self.scroll_to_bottom()\n",
    "            self.click_show_more_results()\n",
    "            \n",
    "            self.generate_otp() \n",
    "            otp = input('Enter OTP\\n')\n",
    "            self.enter_otp(otp)\n",
    "            for i in range(10):\n",
    "                time.sleep(5)\n",
    "                self.click_show_more_results()\n",
    "                time.sleep(5)\n",
    "                self.scroll_to_bottom()\n",
    "            self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            self.scrape_data(search_text)\n",
    "            print(self.df)\n",
    "            self.df.to_excel(f'{search_text}.xlsx')\n",
    "            \n",
    "            \n",
    "            \n",
    "        finally:\n",
    "            #self.df.to_excel(f'{search_text}.xlsx')\n",
    "            self.close_browser()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    driver_path = 'C:/web_driver/chromedriver.exe'\n",
    "    url = 'https://www.indiamart.com/'\n",
    "    excel_file = pd.read_excel('Product-Category.xlsx')\n",
    "    phone_number = '9871308613'\n",
    "    \n",
    "    for i in range (len(excel_file)):\n",
    "        if excel_file['Status'][i]==\"Scrapped\":\n",
    "            continue\n",
    "            \n",
    "        search_text=excel_file['Seller'][i]\n",
    "        scraper = IndiaMartScraper(driver_path)\n",
    "        scraper.run(url, search_text, phone_number)\n",
    "        #excel_file['Status'][i]='Scrapped'\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a5791",
   "metadata": {},
   "source": [
    "# Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff151736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified Excel files have been aggregated into Indiamart-28-Jun.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def aggregate_specific_excel_files(input_directory, output_file, file_list):\n",
    "    # Create an empty DataFrame to hold all the data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through all the files in the input directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename in file_list:\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            df = pd.read_excel(file_path)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    # Write the combined DataFrame to an output Excel file\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = r'C:\\Users\\user\\Desktop\\Data\\Personal\\Portfolio-Projects\\Indiamart'  # Replace with your directory containing Excel files\n",
    "    output_file = 'Indiamart-28-Jun.xlsx'  # Output file name\n",
    "    file_list = ['TOY_MODEL_VEHICLE_TRACK.xlsx',\n",
    "'TOY_VEHICLE_SET.xlsx',\n",
    "'Travel Pillows.xlsx',\n",
    "'TWO WAY RADIO.xlsx',\n",
    "'UNDERPANTS.xlsx',\n",
    "'Vehicle Parts.xlsx',\n",
    "'WINDOW_FILM.xlsx',\n",
    "'WINDOW_SHADE.xlsx',\n",
    "'Noodles brand.xlsx',\n",
    "'Maggi.xlsx',\n",
    "'Sunfeast Yippee Noodles.xlsx',\n",
    "'Knorr Soupy Noodles.xlsx',\n",
    "'Top Ramen.xlsx',\n",
    "'Chingâ€™s Secret Instant Noodles.xlsx',\n",
    "'Patanjali Atta Noodles.xlsx',\n",
    "'Wai Wai Noodles.xlsx',\n",
    "'Horlicks Foodles.xlsx',\n",
    "'Biscuit Brand.xlsx',\n",
    "'Parle-G.xlsx',\n",
    "'Britannia Biscuits.xlsx',\n",
    "'Sunfeast Biscuits.xlsx',\n",
    "'Parle Hide & Seek Biscuits.xlsx',\n",
    "'Mcvities Biscuit.xlsx',\n",
    "'Parle Krack Jack Biscuits.xlsx',\n",
    "'Oreo.xlsx',\n",
    " \n",
    "]  # Replace with the list of specific file names\n",
    "\n",
    "    aggregate_specific_excel_files(input_directory, output_file, file_list)\n",
    "    print(f\"Specified Excel files have been aggregated into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad938bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
